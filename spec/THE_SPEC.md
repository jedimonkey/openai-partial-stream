# Partial Stream Spec

Turn a stream of token into a parsable JSON object as soon as possible.

## Introduction

Partial Stream Spec is a specification for a stream of raw text or structured JSON that can be partially parsed and return early results for an early consumption.

Use cases are:
- LLM stream of token as JSON format.
- OpenAI Function calling, handling stream of data.
- Improve UI/UX by showing partial results to the end user.

## Objectives

Return early results as soon as possible into a parsable JSON foramt.
With the raise of LLM and API that produce a stream of text data and where new use case are emerging like OpenAI Function Calling.
Even if the stream of the data is enable on those API the data still need to be entirely arrived to be able to parse it for using it.

Because it's a stream of token the JSON payload arrive in chunks that are not valid JSON until the end of the stream.
If we accumuluate the chunks and try to parse it it will fails due to malformated JSON because still incomplete.

The goal if to be able to use the JSON object when some part are ready to be used.

For example some keys and values could have arrived already and we can already use it to display it to the end user or to perform any action.

This early processing can be enable by always returning a valid JSON object even if it's **not data complete**.


## Example

Let's say I have a function that return the name of a file to create with it's content generated by the LLM.
In that case the content can be long to arrive, but I can already create the file in the meantime.

```
// The entire payload I'm expecting to receive
{
    "filename": "my_file.txt",
    "content": "Hello World"
}

// The stream of tokens:
// Part 1 -- Malformed JSON -- No Keys and Values available
// Nothing can be done with it yet
{
    "filena


// Part 2 -- Malformed JSON -- Key: Filename and it's value is available
// We can already create the file
{
    "filename": "my_file.txt",
    "conte


// Part 3 -- Malformed JSON -- Key: Content and partial of it's value available.
// We can start writting to the file
{
    "filename": "my_file.txt",
    "content": "Hello


// Part 4 -- Well formated JSON -- Everything is available
// We can close the file
{
    "filename": "my_file.txt",
    "content": "Hello World"
}
```

The goal is to be able to consume this partial JSON.
To enable this we will always return a valid JSON object even if the data is not complete yet.
And we will progressively provide it when it become available.


The objective is to simplify the developer experience by not having to deal with the stream of token and the parsing of it.


As a stream of text when it is to be read by a human a character/words/token is fine to be read and understood. But when we want to base some action on it and be handled by a function or other system it need to be parsable and some how correct in certain extend.

Let take the example of the file creation again.

If we are based on the JSON keys to perform some action we need to have the keys available to be able to perform the action.

For example if the payload is only
```
{
    "filena

```
We can not be sure it will be the correct key for the action or even so if it's in the middle of the filename.
```
{
    "filename": "my_fil
```
We can not create the file because we don't know yet which file to create.

So we need different level of parsing to be able to perform certain action.

Because the key is the principal component we want to wait to have at least 
the entire key before returning a partial JSON.

For example we can return this:

```json
{
    "filename": "my_file.txt"
}
```
Where we now have the key and value to create the file. But we don't have the content yet. but this is fine because we can already create the file.
And this mode is the **Progressive** mode.

When the content arrive we can add it to the payload, same we will need the entire key beforing providing the valid JSON.
```json
{
    "filename": "my_file.txt",
    "content": "Hello world"
}
```
Now we can start writting to the file.


As well another mode it the realtime mode where the content is streamed as well but in a valid JSON.

For example it is useful to start writting to the file as soon as the content is available.

```json

// Partial content
{
    "filename": "my_file.txt",
    "content": "Hello w"
}
```

```json
// Completed content
{
    "filename": "my_file.txt",
    "content": "Hello world"
}
```

This mode is the **Realtime** mode



Another mode is the One-by-one mode where each entity (json object) is returned one by one, it waits to be completed with all the keys and values before returning it.

For example if we have an array of object we can return each object one by one when it's completed.

This is the overall payload:
```json
[
    {
        "filename": "my_file.txt",
        "content": "Hello world"
    },
    {
        "filename": "my_file2.txt",
        "content": "Awesomeness"
    }
]
```

This is the first object returned:
```json
{
    "filename": "my_file.txt",
    "content": "Hello world"
}
```

This is the second object returned:
```json
{
    "filename": "my_file2.txt",
    "content": "Awesomeness"
}
```

This mode is the **One-by-one** mode


<!-- We can as well have a mix of all those mode where we can have a progressive mode for certain key and a realtime mode for certain value. -->


We can as well have a mode where we still want all the data to arrive together or even as a batch.




## Specification



## Feature

- Stream of chunk of json
- Json can have any shape
- Process partial json
- Iterate over array
- Each element of an array is an individual entity
- Detect when an entity is COMPLETED
- Detect when the entity have an ERROR
- Produce only when changes
- Always valid JSON

